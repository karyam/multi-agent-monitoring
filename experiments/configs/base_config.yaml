# Base configuration for all experiments

# Experiment metadata
experiment:
  name: default_experiment
  description: Default experiment configuration
  tracking:
    enabled: true
    platform: wandb  # Options: mlflow, wandb, none
    project_name: multi-agent-monitoring
    log_artifacts: true
    log_system_info: true

# Execution settings
execution:
  # Whether to run the experiment in parallel
  parallel: false
  
  # Number of worker processes to use for parallel execution
  num_workers: 1
  
  # Number of trials to run for the experiment
  num_trials: 3
  
  # Random seed for reproducibility
  random_seed: 42
  
  # Whether to use Ray for parallel execution
  use_ray: false
  
  # Enable debug mode for detailed logging and error messages
  debug_mode: false

# Model settings
model:
  agent_model:
    name: gpt-3.5-turbo
    system_prompt: "You are a rational agent participating in a multi-agent game."
    max_tokens: 500
  gm_model:
    name: gpt-3.5-turbo
    system_prompt: "You are managing a multi-agent game environment."
    max_tokens: 500

# Environment settings
environment:
  type: prisoners_dilemma  # The environment type to use e.g. state_formation, cyber_security, prisoners_dilemma
  settings:
    rounds: 5
    # Add other environment-specific settings

# Agent settings
agents:
  num_agents: 3
  agent_module: null  # If null, uses the default agent module

# Evaluation settings
evaluation:
  metrics:
    - cooperation_rate
    - feature_score
  # File path to properties of interest
  properties: null
    
# Logging settings
logging:
  level: INFO
  log_to_file: true
  metrics:
    - agent_scores
    - cooperation_rate
    - feature_scores
  custom_metrics: []

# Visualization settings
# TBD based on what wandb provides